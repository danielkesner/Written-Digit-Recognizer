# Written-Digit-Classifier

In this project, I trained a neural network in Matlab to recognize handwritten numerical digits. The data used to train the neural network came from UCI's publically available Machine Learning Repository, an online resource hosting datasets for public use. More specific information on the dataset can be found at the website linked below. I used Java to pre-process the image, and Matlab's neural network suite (nnstart and its variants) to train the neural network used to classify images.

Here is a brief explanation of the files contained in this repository and their use:

/src/data: Contains data that can be used to train and test the performance of the network. The data folder is broken into three subfolders: raw, processed, and training. /src/data/training contains a text file called semeion.data which contains 1593 records of handwritten digits. Each row of the text file contains binary, black/white pixel values of the post-processed image followed by a 10-digit classifier string used to teach the neural network which digit (0 ... 9) the previous 256 values correspond to. .../data/processed/ and .../data/raw/ contain a series of images taken on a consumer smartphone that were used to test network performance. The 'raw' folder contains the original, non-processed images, and the 'processed' folder contains images that have had some transformation applied to them.

/src/frontend: Contains Grid.java, a class which uses Java Swing to draw a two-dimensional 16x16 representation of a given image. Grid.java reads a specified line of the semeion.data file and draws the image associated with that string of pixels.

/src/backend: Contains two classes, ImageResizer and ImageProcessor. ImageResizer is used to scale the size of photos initially taken on the smartphone to be 16x16 pixels so that they can be used by the neural network. ImageProcessor is the main class that should be used to do all preprocessing work. First, images should be converted to black and white via Preprocessor.convertToBlackAndWhite(), then scaled to 16x16 via ImageResizer.resize(). Finally, once the images are converted to black/white and scaled to 16x16, you can use ImageProcessor.getPixelVector() to get a 256-element vector of binary pixel values, where 1 is black and 0 is white. This is the same 256-element vector that is used to train (and be used by) the Matlab neural network. ImageProcessor also contains other methods that are helpful for this project.

/src/matlab: Contains a Matlab workspace (Char_Recognition_Workspace.mat) that has a trained neural network object called Sem_Network. Once this workspace has been loaded inside Matlab, you can use it by storing a pixel string (i.e., one of the lines from semeion.data or obtained from ImageProcessor.getPixelVector()) as a Matlab vector and then calling Sem_Network(vector). This will output a 1x10 vector of probabilities, where the first vector element is the probability that the network identified that image as the digit '0', the second element is the digit '1', and so on. 

The data used comes from: https://archive.ics.uci.edu/ml/datasets/Semeion+Handwritten+Digit. The UCI page also contains a more in-depth explanation of the semeion.data dataset used to train the network. My thanks to Tactile Srl for making the data publically available.
